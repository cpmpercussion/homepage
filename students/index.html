<!DOCTYPE html>
<html lang="en-AU">
  <head>
	  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Students</title>
<meta name="description" content="">
<!-- favicons --> 
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#e0e0e0">
<!-- styles --> 
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
<link rel="stylesheet" href="/assets/css/academicons.min.css" />
<link rel="stylesheet" type="text/css" href='/assets/css/main.css'>
<!-- Bootstrap CSS -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-aFq/bzH65dt+w6FI2ooMVUpc+21e0SRygnTpmBvdBgSdnuTN7QbdgL+OapgHtvPp" crossorigin="anonymous">

  </head>
  <body>
    <nav class="navbar navbar-expand-lg bg-dark" data-bs-theme="dark">
  <div class="container-fluid">
  <a class="navbar-brand" href="#">
    <img src="/assets/images/cpm-logo-white.svg" width="40" class="d-inline-block align-top" alt="Logo">
    cpm
  </a>
  <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
  <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse justify-content-between" id="navbarNav">
    <ul class="navbar-nav">
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/">home</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/blog/">blog</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/bio/">bio</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/music/">music</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/publications/">publications</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/projects/">projects</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/lab/">lab</a>
      </li>
      
    </ul>

    <ul class="navbar-nav">
      <li class="nav-item">
	      <a rel="me" href="https://aus.social/@charlesmartin" class="nav-link">
		      <i class="fab fa-mastodon"></i></a>
</li>
      <li class="nav-item">
	      <a href="https://pixelfed.au/charlesmartin" class="nav-link">
		      <i class="fa fa-camera"></i></a>
</li>
      <li class="nav-item">
	      <a href="https://github.com/cpmpercussion" class="nav-link">
		      <i class="fab fa-github"></i></a>
</li>
      <li class="nav-item">
	      <a href="https://charlesmartin.bandcamp.com/" class="nav-link">
		      <i class="fab fa-bandcamp"></i></a>
</li>
      <li class="nav-item">
	      <a href="https://scholar.google.no/citations?user=mTlH4G8AAAAJ" class="nav-link">
		      <i class="ai ai-google-scholar-square"></i></a>
</li>
    </ul>
  </div>
  </div>
</nav>
<!-- unlisted links -->
<a rel="me" href="https://mastodon.acm.org/@charlesmartin"></a>


    <div class="p-5 mb-4 rounded-3 bg-transparent text-light text-center d-flex align-items-center">
      <h1 class="heading-logo display-2 mx-auto">Charles Martin</h1>
    </div>

    

	  <div class="container bg-white rounded">	   
	    <main class="p-4" aria-label="Content">
		    <article>
  
  <div class="my-4 py-4">
    <h1 class="display-5">Students</h1>
  </div>
  

  

  <p><img src="/assets/images/performing/metatone-header.jpg" alt="Teaching header, a metatone performance with friends"></p>

<p><strong>Currently Recruiting!</strong> I’m currently looking for <strong>PhD students</strong> in the field of musical machine learning, particularly for projects focussed on using AI/ML in live performance!</p>

<p>If you’re passionate about <em>music, machine learning, and computer science</em> (or some weighting of those three fields), and want to be a part of <a href="https://cecs.anu.edu.au/reimagine">an innovative college</a> at one of the <a href="https://services.anu.edu.au/planning-governance/performance-measurement/world-rankings">world’s top universities</a>, get in touch through <a href="https://cecs.anu.edu.au/people/charles-martin">ANU</a>, or on <a href="https://twitter.com/cpmpercussion">Twitter</a>!</p>

<h2 id="courses">Courses</h2>

<p>I currently teach:</p>

<ul>
  <li>
<a href="https://cs.anu.edu.au/courses/comp1720">Art and Interaction in New Media (COMP1720)</a> (S2 2020)</li>
  <li>
<a href="https://cs.anu.edu.au/courses/comp2710-lens/">Laptop Ensemble (COMP2710-LENS)</a> at the Australian National University (S2 2019, S1 2020)</li>
  <li>
<a href="https://cs.anu.edu.au/courses/comp2300">Computer Organisation and Program Execution
(COMP2300)</a> at the Australian National University (S1 2019, S1 2020).</li>
</ul>

<p>I used to teach:</p>

<ul>
  <li>
<a href="https://www.uio.no/studier/emner/matnat/ifi/IN5490">Advanced Topics in AI for Intelligent Systems (IN5490)</a> at the University of Oslo,</li>
  <li>
<a href="https://music.cass.anu.edu.au/performance-ensemble/drums-and-percussion">Drums and Percussion at the ANU School of Music</a>.</li>
</ul>

<p><img src="/assets/images/teaching/bela-workshop-header.jpg" alt="teaching a group"></p>

<h2 id="research-students">Research Students</h2>

<p>I supervise and co-supervise PhD and Master’s students at the ANU and at University of Oslo. My previous students’ published work is <a href="/lab/grads/">listed here</a>.</p>

<h3 id="phd-students-co-supervisor">PhD Students (co-supervisor):</h3>

<ul>
  <li>
<strong>Tønnes Nygaard</strong> (http://robotikk.net/) is studying evolutionary robotics at the University of Oslo, Department of Informatics and has created a open-source quadruped robotics platform with mechanically extensible legs for evolving control systems and robot morphology simultaneously during real-world activity. (2018-2020)</li>
  <li>
<strong>Benedikte Wallace</strong> (https://www.hf.uio.no/ritmo/english/people/phd-fellows/benediwa/) is studying machine learning models of sound-related movement and dance, among other creative applications of artificial intelligence, at the RITMO Centre of Excellence, University of Oslo. (2018-2021)</li>
</ul>

<h2 id="student-projects">Student Projects</h2>

<p class="info-box">I’m not recruiting student projects in 2023!</p>

<p>I supervise student projects in sound and music computing, creativity support systems, computational creativity, music technology, and interactive systems. I’m interested in creating and studying new computing systems at the nexus of creative arts, physical embodiment, interaction, and intelligence.</p>

<p>Projects could involve:</p>

<ul>
  <li>developing predictive musical instruments</li>
  <li>new interfaces for musical expression (NIME)</li>
  <li>machine learning of musical style</li>
  <li>musical AI</li>
  <li>computer support for collaborative musical expression</li>
  <li>applying ML/AI in creative practices</li>
</ul>

<p><img src="/assets/images/charlesmartin-background.jpg" alt="Charles Martin Background Areas"></p>

<p>Here’s some project ideas that could be extended or shaped to suit you:</p>

<h3 id="creating-a-new-interface-for-musical-expression">Creating a New Interface for Musical Expression</h3>

<p>Computers and electronics give us so many new opportunities to create new kinds of musical instruments (and new kinds of music). We often think of these systems as containing an <em>interface</em> between a human user and sound synthesisers. The interface can either be a piece of computer software (e.g., a web app, or a p5.js program), or hardware (e.g., an Arduino with custom sensors). <a href="https://nime.org">New Interfaces for Musical Expression</a> is a research field where we explore how these new software and hardware-based instruments work and what kinds of music they can make.</p>

<p>I’ve created <em>lots</em> of different kinds of new musical interfaces, but in this project, it’s a good opportunity to create something that you invent or to take a new idea further than it has been before.</p>

<h3 id="requirements">Requirements:</h3>

<ul>
  <li>strong interest in music and interaction</li>
</ul>

<h3 id="nice-to-have">Nice to have:</h3>

<ul>
  <li>experience in hardware (e.g., Arduino)</li>
  <li>experience in interactive media software (e.g., <a href="p5js.org">p5.js</a>)</li>
  <li>experience in computer music (e.g., <a href="https://cs.anu.edu.au/courses/comp2710-lens/">ANU Laptop Ensemble</a>) or creative arts (e.g., <a href="https://cs.anu.edu.au/courses/comp1720/">Art and Interaction Computing</a>).</li>
</ul>

<h3 id="discriminating-real-from-neural-generated-music">Discriminating real from neural generated music</h3>

<p>Most generative music systems just create new music, this project would involve training discriminator neural networks to tell if music was created by a human, or a cutting edge ANN such as <a href="https://magenta.tensorflow.org/music-transformer">Music Transformer</a> or <a href="https://magenta.tensorflow.org/performance-rnn">PerformanceRNN</a>.</p>

<h3 id="generating-harmony-from-melody">Generating Harmony from Melody</h3>

<p>This project involves creating a sequence-to-sequence ANN that can generate harmony, or counter-melodic parts for a given melody. The focus here would be to deploy this network in a music creating app such as <a href="https://microjam.info">MicroJam</a>.</p>

<h3 id="generating-improved-versions-of-a-melodymidi-content">Generating “improved” versions of a melody/MIDI content</h3>

<p>The idea of this project is to take an existing melody created in an interactive music system and change its style, or improve it in some way. It could involve modifying the melody to fit a particular harmony, or create a more appealing melodic shape. Various sequence-to-sequence ANN techniques could be applied here, and such a system could have applications in musical performance and education.</p>

<h3 id="neural-networks-for-generating-digital-audio">Neural Networks for Generating Digital Audio</h3>

<p>The idea of generating digital audio directly from a neural network is exciting and there are stunning results from examples such as <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">Wavenet</a>, <a href="https://arxiv.org/abs/1612.07837">SampleRNN</a>, <a href="https://gfx.cs.princeton.edu/pubs/Jin_2018_FAR/">FFTNet</a>, and <a href="https://github.com/chrisdonahue/wavegan">WaveGan</a>. Projects in this area will involve finding new application areas for neural audio generation and developing focussed and fast algorithms with appropriate training data for use in these areas. In particular, the use of these networks for creative arts is still being actively explored.</p>

<h3 id="evolutionary-music-making">Evolutionary Music Making</h3>

<p><a href="https://en.wikipedia.org/wiki/Evolutionary_music">Making music with evolutionary algorithms</a> has a long history, but is yet to break into mainstream music technology systems. In this project, you will develop an interactive music application (e.g., web or mobile app) for generating and assessing music created using an evolutionary algorithm. A novel approach might involve the human user evaluating some generated sounds, while others are analysed by an automatic system using MIR techniques or a discriminator neural network.</p>

<h3 id="new-applications-of-the-mixture-density-recurrent-neural-network">New Applications of the Mixture Density Recurrent Neural Network</h3>

<p>The MDRNN is an exciting sequence model that can generate multiple continuous valued signals from a Gaussian mixture model at each step in time. This project will involve applying and extending my <a href="https://github.com/cpmpercussion/keras-mdn-layer">Keras MDRNN models</a> into new applications in the creative arts and beyond. We’ve tried using the MDRNN for voice synthesis, motion capture data synthesis, and musical control data synthesis, but there are lots of other potential applications waiting for you to discover, e.g.: predicting future sensor values, generating robot movements, generating world models for video games or real life situations etc.</p>


</article>


	    </main>
	  </div>
    <footer class="text-light text-center py-5">
  © Charles P. Martin 2022
  <a rel="me" href="https://mastodon.acm.org/@charlesmartin"></a>
</footer>

	  
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha2/dist/js/bootstrap.bundle.min.js" integrity="sha384-qKXV1j0HvMUeCBQ+QVp7JcfGl760yU08IQ+GpUo5hlbpg51QRiuqHAJz8+BrxE/N" crossorigin="anonymous"></script>

  </body>
</html>
