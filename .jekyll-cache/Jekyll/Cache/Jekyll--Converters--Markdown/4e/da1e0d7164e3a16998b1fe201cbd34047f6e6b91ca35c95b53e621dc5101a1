I"<h3 id="we-need-your-help-to-study-an-ai-enhanced-musical-instrument">We need your help to study an AI-enhanced musical instrument!</h3>

<p><img src="/assets/images/research/empi-v3.jpg" alt="EMPI- an AI-enhanced musical instrument" /></p>

<p>Charles Martin has been creating new AI-enhanced musical instruments at the ANU Research School of Computer Science. Now it’s time to try it out with real musicians!</p>

<p>In this experiment, you will perform six short improvisations with a new musical instrument (see video above), fill out short surveys after each improvisation, and have a short discussion afterwards. The session should take about 25 minutes. There’s more information about the study at the bottom of the page.</p>

<p>Hopefully it will be a fun experience with experimental music, and Charles will buy you a coffee (or other hot drink) as thanks!</p>

<p>Express your interest here by October 11, 2019!</p>

<p>Fill in the form below (or <a href="https://forms.gle/bnTxLdEHc5kndfHY6">click this link</a>)</p>

<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeOLzqGdAVUT7pn9OMYwK5Fpks40z86QPevrTTJduKRyiHluA/viewform?embedded=true" width="640" height="1056" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>

<p>Here’s the instrument you’ll try out:</p>

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style>
<div class="embed-container"><iframe src="https://www.youtube.com/embed/SX6dTE0vLSk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></div>

<!-- https://youtu.be/SX6dTE0vLSk -->

<h2 id="participant-information-sheet">Participant Information Sheet</h2>

<h3 id="project-title">Project Title:</h3>

<p>Understanding Musical Interaction with Machine Learning-Enhanced Interfaces.</p>

<h3 id="general-outline-of-the-project">General Outline of the Project:</h3>

<p>This project is an investigation into musical performance with computer-based instruments that interact with predictive machine learning (ML) models. We have developed an instrument that allows a musician to perform music along with an ML algorithm. The algorithm listens to your performance and responds when you stop playing. You can improvise with it as you would a duet partner.</p>

<p>Participants in this project will perform using this computer instrument. We will study both the artistic output (recordings of performances and rehearsals) and the participant’s experiences using the instruments (collected through surveys and interviews). We hope to develop an increased understanding of musical performance with machine learning enhanced instruments and evaluate their effectiveness.</p>

<p>Data from this project will be published in the researcher’s journal and conference publications and may be used to develop new machine learning algorithms.</p>

<h3 id="participant-involvement">Participant Involvement:</h3>

<p>Participants will take part in a rehearsal using a ML-enhanced musical instrument in a recording studio environment. After an orientation and trial improvisation, they will perform six short improvisations using different configurations of the software instrument we have developed.</p>

<p>We will ask participants to fill in a short (1 minute) survey after rehearsing each piece and 1 minute surveys at the start and end of the session. After the session we will ask participants to participate in a five minute interview related to their experience which will be recorded. All rehearsals in this project will be audio and video recorded and interactions with the computer music instruments will also be recorded.</p>

<ul>
  <li><em>Publication of Artistic Works</em>: We may publish video and sound recordings of musical works on the internet and credit participants. On the consent form we ask for permission to publish these works. Participants will retain performer’s copyright over their recorded performances.</li>
  <li><em>Use of data in machine-learning systems</em>: We may use interaction data from the session to improve the instruments and these data may be released publicly in de-identified form.</li>
  <li><em>Voluntary Participation &amp; Withdrawal</em>: Participation in this study is entirely voluntary. If you wish to withdraw we will not publish or report your survey and interview responses or interaction data. If you wish to withdraw please contact Charles Martin.</li>
</ul>

<h3 id="researcher">Researcher:</h3>

<p>Charles Martin is a Lecturer at the College of Engineering and Computer Science at the Australian National University, Canberra. He is a researcher and teacher in the fields of computer music, machine learning and human-computer interaction. Charles has performed throughout Australia, Europe and the USA and has been involved in music technology research at institutions in Sweden, Norway, and Australia.</p>

<h3 id="location-and-duration">Location and Duration:</h3>

<p>Location: Studio 1 (Room 2.05), Peter Karmel Building, ANU School of Music, or Room 4.24, Hanna Neumann Building 145, ANU.</p>

<p>Duration: 25 minutes.</p>

<p>Date and Time for this study will be negotiated with the participants but are expected to take place between 1/10/2019 and 31/10/2019.</p>

<h3 id="confidentiality">Confidentiality</h3>

<p>Research publications of this study will include statistics derived from the participants’ survey responses as well as quotations of comments the participants may make during rehearsal discussions and interviews. In the consent form, you may give us permission to have your interview responses attributed to your full name, a pseudonym, or kept confidential.</p>

<p>All performance involves a level of reputational risk so we ask participants to consent to publication of each recorded musical work credited to their full name, and for the inclusion of interaction data in a public dataset. We will not publish data if you do not give us permission. We would ask that you participate in this research only if you feel generally comfortable with publishing your performances and having interaction data included in machine learning models.</p>

<p>Data collected during this research will only be accessible to the researcher and kept confidential as far as the law allows.</p>

<h3 id="data-storage">Data Storage:</h3>

<ul>
  <li>Data will be stored at the ANU College of Engineering and Computer Science.</li>
  <li>Survey and interview data and consent forms will be stored for five years after any publications of this research, after this time they will be destroyed.</li>
</ul>

<h3 id="queries-and-concerns">Queries and Concerns:</h3>

<p>For more information, feel free to contact Dr Charles Martin at the ANU:</p>

<p><strong>Dr Charles Martin </strong> <br />
Hanna Neumann Blg 145, 4.19<br />
 Telephone: 6125 3139<br />
Email:  charles.martin@anu.edu.au</p>

<h3 id="ethics-committee-clearance">Ethics Committee Clearance:</h3>

<p>The ethical aspects of this research have been approved by the ANU Human Research Ethics Committee. If you have any concerns or complaints about how this research has been conducted, please contact:</p>

<p><strong>Ethics Manager </strong><br />
The ANU Human Research Ethics Committee <br />
The Australian National University <br />
Telephone: +61 2 6125 3427 <br />
Email: Human.Ethics.Officer@anu.edu.au</p>
:ET