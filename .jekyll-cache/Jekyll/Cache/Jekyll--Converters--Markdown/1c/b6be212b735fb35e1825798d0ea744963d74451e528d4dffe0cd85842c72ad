I"˜#<p>I‚Äôve just gotten back from NIME2015 in Baton Rouge where I presented a poster about my performance tracking system for iPad ensembles. Great to catch up with new and old NIMErs! The paper is 
<a href="https://nime2015.lsu.edu/proceedings/242/index.html">available here</a> and here‚Äôs the text of the poster:</p>

<h2 id="metatone-classifier">Metatone Classifier</h2>

<p>We have designed a server-based agent called Metatone Classifier that tracks musical interaction on touch screen apps and makes calculated adjustments to the performers‚Äô interfaces. Our agent interacts with an iPad ensemble performing on apps that respond by updating their user interface.</p>

<p>The aim of our system is to present an ‚Äúinterface-free interface‚Äù to the performers where their touch-gestures during an improvisation or composed work are used to adjust pitches, effects, and sonic material. We have developed several iPad apps that interact with our agent and used them in ensemble performances with two to seven performers.</p>

<p>During a performance, our agent observes touch-screen interactions and classifies them as a sequence of gestural states. It estimates the occurrence of new ideas across the ensemble by calculating a measure, flux, on the transition matrix of these gesture states.</p>

<h2 id="system-design">System Design</h2>

<p><img src="/assets/squarespaceblog/2015-06-07_Figure1-SystemDiagram.jpg" alt="The system layout of a Metatone Classifier and iPad Ensemble performance." /></p>

<p>(The system layout of a Metatone Classifier and iPad Ensemble performance.)</p>

<p>Metatone Classifier consists of a Python application which runs on a
laptop computer or on a remote server. During performances, the
ensemble‚Äôs iPad apps connect to the server over a Wi-Fi network using
Bonjour. Once connected the iPad apps send logs of each touch event to
the agent using the OSC message format. The agent analyses the
performances of all connected iPads and returns information once per
second.</p>

<p>Two kinds of information are returned to the performers‚Äô iPads: a
classification of the performers‚Äô recent touches into one of nine
gesture classes, and whether a ‚Äúnew idea‚Äù has been detected in the
ensemble. Gesture classification is performed using a Random Forest
classifier. Identifying new-ideas in the performance involves
calculating a matrix of the performers‚Äô recent transitions between
gestures classes and applying a matrix measure, flux, to these
transition matrices.</p>

<p>We have evaluated the time-complexity of Metatone Classifier tracking
from zero to four performers playing simultaneously. The mean time to
complete an analysis had a significant (p &lt; 0.001) linear relationship
with the number of performers so we were able to estimate that an
ensemble of 25 iPads could be an upper bound for the present system to
perform an analysis each second.</p>

<p><img src="/assets/squarespaceblog/2015-06-07_Fig2-PerfVsTime.jpg" alt="The time-complexity of running our classification system increased linearly with the number of players. We benchmarked the software using¬† from 0 to 4 simultaneous iPad performers and would expect our current software to run with up to around 25 iPads." /></p>

<p>(The time-complexity of running our classification system increased linearly with the number of players. We benchmarked the software using¬† from 0 to 4 simultaneous iPad performers and would expect our current software to run with up to around 25 iPads.)</p>

<h2 id="touch-gestures-and-gesture-classifier">Touch Gestures and Gesture Classifier</h2>

<p><img src="/assets/squarespaceblog/2015-06-07_Fig3-Transitions.jpg" alt="The gesture classifications and new idea messages sent during a performance. Each line represents a different performer." /></p>

<p>(The gesture classifications and new idea messages sent during a performance. Each line represents a different performer.)</p>

<p>Metatone Classifier uses a vocabulary of nine continuous, percussive touch gestures that were identified in a previous qualitative study of iPad improvisations by percussionists. Descriptive statistics are calculated from a sliding five-second window of each performer‚Äôs touch data and classified using a Random Forest classifier.</p>

<p>Two prototype versions of the classifier were trained using examples of each gesture from a studio performance but the current version uses gestures captured in a formal procedure. An evaluation using ten applications of stratified 10-fold cross validation was performed on each of these classifiers. The classifier that was trained using formally collected data had the highest accuracy (Mean = 0.973 S.D. = 0.022) and the effect of formal data-collection on accuracy was found to be significant through a one-way ANOVA procedure (F(2,297) = 31.7, p &lt; 0.001).</p>

<p><img src="/assets/squarespaceblog/2015-06-07_Fig4-MetatonePerformance.jpg" alt="Ensemble Metatone performing on iPads as a septet." /> Ensemble Metatone performing on iPads as a septet.</p>

<p><img src="/assets/squarespaceblog/2015-06-07_Fig5-CrossVal.jpg" alt="The cross-validation accuracy of three data sets for our Gesture Classifier. The formal procedure had a significantly higher accuracy despite having a similar number of¬†samples as other methods." /></p>

<p>(The cross-validation accuracy of three data sets for our Gesture Classifier. The formal procedure had a significantly higher accuracy despite having a similar number of¬†samples as other methods.)</p>

<h3 id="gesture-classes">Gesture Classes:</h3>

<ul>
  <li>n: None</li>
  <li>ft: Fast Taps</li>
  <li>st: Slow Taps</li>
  <li>fs: Fast Swipes</li>
  <li>fsa: Accelerating Swipes</li>
  <li>vss: Very Slow Swirls</li>
  <li>bs: Big Swirls</li>
  <li>ss: Small Swirls</li>
  <li>c: Combinations</li>
</ul>

<h2 id="transition-matrices-and-flux-and-new-ideas">Transition Matrices and Flux (and New Ideas)</h2>

<p><img src="/assets/squarespaceblog/2015-06-07_Fig7-ANUEMS.jpg" alt="" /></p>

<p>The ANU New Music Ensemble performing with Metatone Classifier and PhaseRings (Photo: Chlo√´ Hobbs).</p>

<p>A transition matrix of all performers‚Äô touch interactions is used to summarise the behaviour of the whole ensemble and identify moments of peak gestural change. Each musicians‚Äô gesture activity over a performance can be represented as a sequence of gestural states, and a transition matrix can be calculated as for a first order Markov chain. The transition matrix of the whole ensemble is the average of each performer‚Äôs transition matrix.</p>

<p><img src="/assets/squarespaceblog/2015-06-07_Fig8-GestureTransition.jpg" alt="" /></p>

<p>A gesture transition matrix for a 15-second window represented as a heat map. Higher values on the diagonal indicate static gestural activity while off-diagonal indicates gestural movement in the ensemble. Our flux measure exposes this as a single value between 0 and 1.</p>

\[\begin{align*}
\mathrm{flux}(P) &amp;= \frac{\|P\|_1-\|\mathrm{diag}(P)\|}{\|P\|_1}\\
|P\|_1 &amp;= \sum_{i,j}|p_{ij}| \text{  (1-norm of matrix } P \text{)}\\
\mathrm{diag}(P) &amp;\text{ is the vector of diagonal entries in } P 
\end{align*}\]

<p>The definition of our flux matrix measure. The value of flux(P) is in the interval [0,1], where 0 represents completely static ensemble activity and 1 represents maximum gestural change.</p>

<p>Our agent calculates the ensemble transition matrix over 15 second windows to examine how transition activity changes throughout the performance. We use a matrix measure called ‚Äúflux‚Äù to compare this activity. Flux is a measure of how frequently performers change gesture over this window and returns a value in the range [0,1]. When a flux reading exceeds the previous window by a certain threshold, a ‚Äúnew-idea‚Äù event is sent to the performers‚Äô iPads.</p>

<h2 id="phaserings">PhaseRings</h2>

<p><img src="/assets/squarespaceblog/2015-06-07_Figure6-PhaseRingsScreen.png" alt="PhaseRings - an annular interface that for ensemble performances mediated by¬†Metatone Classifier.¬†PhaseRings is available for free in the App Store: metatone.net/phaserings" /> PhaseRings - an annular interface that for ensemble performances mediated by¬†Metatone Classifier.¬†PhaseRings is available for free in the App Store: metatone.net/phaserings</p>

<p>PhaseRings is one of our iPad apps designed to interact with Metatone Classifier in ensemble performances. The app consists of an annular interface for performing with percussive samples and pure synthesis sounds. The concentric rings represent different pitches of a single sound source which are selected randomly from a scale.</p>

<p>Tapping a ring will activate a note with a natural decay while swirling on a ring will create a sustained sound. Each player has different pitches chosen from one of a sequence of scales which advance for all performers when a new-idea message is sent to the ensemble or a performer activates a UI element.</p>

<p>As the performers explore different touch gestures, they are rewarded with the opportunity to perform new melodic material with access to new notes and experience a sense of cohesive harmonic progression.</p>
:ET