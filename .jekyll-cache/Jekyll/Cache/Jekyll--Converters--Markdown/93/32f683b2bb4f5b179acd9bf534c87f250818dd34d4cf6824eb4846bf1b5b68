I"Œ<p>I recently had the chance to present a paper about my â€œNeural iPad Ensembleâ€ at the Audio Mostly conference in London. The 
<a href="http://folk.uio.no/charlepm/preprints/2017-AudioMostly-DeepModelsEnsmbleImprovisation.pdf">paper</a>, discusses how machine learning can help to model and create free-improvised music on new interfaces, where the rules of music theory may not fit. I described the Recurrent Neural Network (RNN) design that I used to produce an AI iPad ensemble that responds to a â€œleadâ€ human performer. In the demonstration session, I set up the iPads and RNN and had lots of fun jamming with the conference attendees.</p>
:ET