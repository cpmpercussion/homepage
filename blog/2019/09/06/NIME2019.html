<!DOCTYPE html>
<html lang="en-AU">
  <head>
	  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Musical ML at NIME2019</title>
<meta name="description" content="">
<!-- favicons --> 
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#e0e0e0">
<!-- styles --> 
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
<link rel="stylesheet" href="/assets/css/academicons.min.css" />
<link rel="stylesheet" type="text/css" href='/assets/css/main.css'>
<!-- Bootstrap CSS -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">

  </head>
  <body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
  
  <a class="navbar-brand" href="#">
    <img src="/assets/images/cpm-logo-white.svg" width="40" class="d-inline-block align-top" alt="">
    cpm
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/">home</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/blog/">blog</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/bio/">bio</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/music/">music</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/publications/">publications</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/projects/">projects</a>
      </li>
      
      
      
      <li class="nav-item ">
      <a class="nav-link " href="/lab/">lab</a>
      </li>
      
    </ul>

    <ul class="nav navbar-nav ml-auto">
      <li class="nav-item">
	      <a rel="me" href="https://aus.social/@charlesmartin" class="nav-link">
		      <i class="fab fa-mastodon"></i></a>
</li>
      <li class="nav-item">
	      <a href="https://pixelfed.au/charlesmartin" class="nav-link">
		      <i class="fa fa-camera"></i></a>
</li>
      <li class="nav-item">
	      <a href="https://github.com/cpmpercussion" class="nav-link">
		      <i class="fab fa-github"></i></a>
</li>
      <li class="nav-item">
	      <a href="https://charlesmartin.bandcamp.com/" class="nav-link">
		      <i class="fab fa-bandcamp"></i></a>
</li>
      <li class="nav-item">
	      <a href="https://scholar.google.no/citations?user=mTlH4G8AAAAJ" class="nav-link">
		      <i class="ai ai-google-scholar-square"></i></a>
</li>
    </ul>
    <!-- unlisted links -->
    <a rel="me" href="https://mastodon.acm.org/@charlesmartin"></a>
  </div>
</nav>


    <div class="jumbotron bg-transparent text-light text-center d-flex align-items-center">
      <h1 class="heading-logo display-2 mx-auto">Charles Martin</h1>
    </div>

    

	  <div class="container bg-white rounded">	   
	    <main class="p-4" aria-label="Content">
		    <article>
  <h1>Musical ML at NIME2019</h1>
  <h6 class="font-italic">06 Sep '19</h6>
  <p>I was really excited to be have several submissions accepted at <a href="https://www.ufrgs.br/nime2019/">NIME 2019</a> in Porto Alegre, among several more from the RITMO centre of excellence at UiO. It was really amazing to be at the first NIME in South America and to meet many wonderful musicians and researchers from Brazil and the region.</p>

<h3 id="workshop-in-predictive-nimes">Workshop in Predictive NIMEs</h3>

<p><img src="/assets/blog/2019/NIME2019-workshop.jpg" alt="Creative Prediction Workshop at NIME 2019"></p>

<p>The first event for me was presenting my workshop in Predictive NIMEs on the first day of the conference. This was in tutorial format and broadly followed the presentations and walkthroughs I’ve been developing on <a href="https://creativeprediction.xyz/tutorials/">creativeprediction.xyz</a>. I ended up a bit nervous about it because it was fully subscribed (we had to find some extra chairs) and the attendees included some of my favourite NIME contributors — this just shows that there is certainly an appetite in music technology to explore new ways to use machine learning and particularly deep neural networks.</p>

<p>The best part of this workshop was working with a group of attendees to get my <a href="https://github.com/cpmpercussion/imps">IMPS</a> system up and running. I know at least one or two are now starting to use this in new projects!</p>

<iframe src="https://giphy.com/embed/h73FNuA09RUpuERYJs" width="480" height="270" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe>
<p><a href="https://giphy.com/gifs/h73FNuA09RUpuERYJs">via GIPHY</a></p>

<p>If you’re interested in following the following the workshop materials, <a href="https://creativeprediction.xyz/nime/">they’re online here</a>.</p>

<h3 id="interactive-musical-prediction-system">Interactive Musical Prediction System</h3>

<p>This paper was a bit of a <em>reveal</em> of the tech I’ve been working on throughout my <a href="https://www.hf.uio.no/ritmo/english/projects/all/epec/">postdoc in the EPEC project at UiO</a>.</p>

<p><a href="https://github.com/cpmpercussion/imps">IMPS</a> is a complete system for applying an RNN to predicting musical gesture data in a NIME or other music tech system. The IMPS system consists of an OSC server that receives gestural data and can predict future data using a mixture density recurrent neural network. Rather than using a big dataset, this system is designed to allow musicians and makers to record their own data, train a small MDRNN and start using it as soon as possible. You can use however many dimensions of gestural data you like, and it predicts future events in absolute time (i.e., a number of seconds). It’s easy to connect to environments like Max, Pd, and Processing and even works (kinda) on <em>very</em> small datasets, as shown in the workshop above!</p>

<p><img src="/assets/blog/2019/NIME2019-predictive-interaction-motivation.jp2" alt="IMPS motivation"></p>

<p>The idea of the paper was to introduce IMPS, and show that it’s practical for it to train and predict data for typical NIME-tasks. We show that it’s even practical to run on a Raspberry Pi, as well as train the RNN on a typical laptop (no big GPU workstation required).</p>

<p>I had a great response to this work; I think the NIME community really resonates with the idea of reusable tools so hopefully a few of my colleagues try IMPS out in their own projects!</p>

<p><img src="/assets/blog/2019/NIME2019-impspresentation.jpg" alt="Me presenting my IMPS paper!"></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Martin2019,
  author = {Martin, Charles Patrick and Torresen, Jim},
  title = {An Interactive Musical Prediction System with Mixture Density Recurrent Neural Networks},
  pages = {260--265},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Queiroz, Marcelo and Sedó, Anna Xambó},
  year = {2019},
  month = jun,
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  issn = {2220-4806},
  url = {http://www.nime.org/proceedings/2019/nime2019_paper050.pdf}
}
</code></pre></div></div>

<h3 id="physical-intelligent-instrument">Physical Intelligent Instrument</h3>

<p>This short paper came from Torgrim Næss’ master’s project (now completed!), and described his self-contained RNN music maker. This little box contains a Raspberry Pi, running a melody-generating deep learning model that plays an endless stream of AI music. There are knobs to control the volume, tempo, software synth instrument used to play the notes and two ML-specific knobs: one that controls the “temperature” or sampling diversity, and another to switch between ML models. He included a Bach model, one from a large web-sourced MIDI dataset, and one trained just on Final Fantasy 7 soundtracks.</p>

<p><img src="/assets/blog/2019/NIME2019-Torgrim.jpg" alt="Torgrim presenting his paper and RNN box to an appreciative audience!"></p>

<p>In initial tests, my favourite combination was FF7 and an “orchestra hit” midi synth, but it was great to see NIME-attendees trying out lots of options and thinking of new ways to use this device in musical scenarios. Maybe a little RNN-box orchestra is in order?</p>

<p>Here’s a demo:</p>

<iframe src="https://giphy.com/embed/TKRIuWAYyrhkxZxzEp" width="480" height="270" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe>
<p><a href="https://giphy.com/gifs/ai-ml-rnn-TKRIuWAYyrhkxZxzEp">via GIPHY</a></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Næss2019,
  author = {Næss, Torgrim Rudland and Martin, Charles Patrick},
  title = {A Physical Intelligent Instrument using Recurrent Neural Networks},
  pages = {79--82},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Queiroz, Marcelo and Sedó, Anna Xambó},
  year = {2019},
  month = jun,
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  issn = {2220-4806},
  url = {http://www.nime.org/proceedings/2019/nime2019_paper016.pdf}
}
</code></pre></div></div>

<h3 id="generating-harmony-with-lstm-networks">Generating Harmony with LSTM Networks</h3>

<p><img src="/assets/blog/2019/NIME2019-Harmony.jpg" alt="Generating Harmony Parts at NIME"></p>

<p>Finally, one last paper from a team of students who developed an excellent piece of research on harmonised parts generated by sequence-to-sequence recurrent neural networks during our <a href="https://www.uio.no/studier/emner/matnat/ifi/IN5490/index.html">IN5490 course at UiO</a>, and developed it into a great paper. This paper had a particularly nice introduction to RNN architectures for a music technology audience.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Faitas2019,
  author = {Faitas, Andrei and Baumann, Synne Engdahl and Næss, Torgrim Rudland and Torresen, Jim and Martin, Charles Patrick},
  title = {Generating Convincing Harmony Parts with Simple Long Short-Term Memory Networks},
  pages = {325--330},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Queiroz, Marcelo and Sedó, Anna Xambó},
  year = {2019},
  month = jun,
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  issn = {2220-4806},
  url = {http://www.nime.org/proceedings/2019/nime2019_paper062.pdf}
}
</code></pre></div></div>

<h3 id="presentations-at-ufrgs">Presentations at UFRGS</h3>

<p>After NIME the team from UiO gave a few extra presentations at the Informatics Department at UFRGS, fun to hang out with Bruno in his lab and chat with the students! Here’s Synne and Andrei reprising their NIME presentation:</p>

<p><img src="/assets/blog/2019/NIME2019-AndreiSynne.jpg" alt="Presenting at UFRGS"></p>

<h3 id="shoutouts">Shoutouts</h3>

<p>A couple of shoutouts to my colleagues:</p>

<p>From the RITMO Centre, Cagri Erdem, Alexander Jensenius and Katja Schia had a <a href="http://www.nime.org/proceedings/2019/nime2019_paper037.pdf">paper</a> and performance on their Vrengt music-dance performance research. And also from IN5490, Aline Weber, Lucas Alegre, Jim Torresen, and Bruno Castro da Silva had <a href="http://www.nime.org/proceedings/2019/nime2019_paper035.pdf">a great paper on parametrising melody generation with Perlin noise</a>.</p>

</article>

	    </main>
	  </div>
    <footer class="text-light text-center py-5">
  © Charles P. Martin 2022
  <a rel="me" href="https://mastodon.acm.org/@charlesmartin"></a>
</footer>

	  
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>

  </body>
</html>
